{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Aotizhongxin, Changping, Dingling (Michael) \n",
    " - Dongsi, Guanyuan, Gucheng (David) \n",
    " - Huairou, Nongzhanguan, Shunyi (Muareen) \n",
    " - Tiantan, Wanliu, and Wanghouxigong (Anna)\n",
    " \n",
    " \n",
    " \n",
    " # some work to do:\n",
    "  \n",
    "1. Calculate AQI for each day for PMP10 and PM2.5\n",
    "2. Subset the data into geographic regions\n",
    "    2.1 Subset the data by seasons\n",
    "3. General trend for some attributes?\n",
    "        Create AIQ\n",
    "        Avg number of really bad days?                        \n",
    "4. Make cool looking plots/graphs with the data MAPS!\n",
    "5. Analysis of those plots/graphs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns #visualisation\n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "import seaborn as sns #visualisation\n",
    "%matplotlib inline \n",
    "sns.set(color_codes=True)\n",
    "import plotly.express as px\n",
    "import datetime as dt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "\n",
    "#conda install -c conda-forge ipyleaflet\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, Marker, Heatmap, WidgetControl\n",
    "from bqplot import Lines, Figure, LinearScale, DateScale, Axis\n",
    "from ipywidgets import Dropdown\n",
    "\n",
    "import aqi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and cleaning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_from_string(df_to_clean, month_column, day_column, year_column):\n",
    "    #add correct data column\n",
    "    print('**************************')\n",
    "    print('Creating date column')\n",
    "    print('**************************')\n",
    "    #df_to_clean['date'] = df_to_clean.apply(lambda row: str(row[month_column])+'-'+str(row[day_column])+'-'+str(row[year_column]), axis=1)\n",
    "    df_to_clean['date'] = df_to_clean.apply(lambda row: dt.datetime(row[year_column], row[month_column], row[day_column]), axis=1)\n",
    "    \n",
    "    #df_to_clean['date_2'] =  pd.to_datetime(df_to_clean['date'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df_to_clean):    \n",
    "    print('**************************')\n",
    "    print('Removing Duplicates')\n",
    "    print('**************************')\n",
    "    duplicate_rows_df = df_to_clean[df_to_clean.duplicated()]\n",
    "    print('number of duplicate rows: ', len(duplicate_rows_df.index))\n",
    "    df_to_clean.drop_duplicates(inplace=True)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drop_nulls_from_df(df_to_clean, drop_rows,column_names=[]):\n",
    "    if column_names == []:\n",
    "        column_names == column_names.append(df_to_clean.columns)\n",
    "    print('**************************')\n",
    "    print('Removing Nulls')\n",
    "    print('**************************') \n",
    "    \n",
    "    print('- - - - - - - - - - - - - ')\n",
    "    print('Before removing nulls')\n",
    "    print('- - - - - - - - - - - - - ')\n",
    "    print(df_to_clean.isnull().sum()) # Number of rows with nulls that we are dropping    \n",
    "    \n",
    "    if(drop_rows):\n",
    "        df_to_clean.dropna(inplace=True, subset=column_names) \n",
    "    \n",
    "    \n",
    "    print('- - - - - - - - - - - - - ')\n",
    "    print('After removing nulls')\n",
    "    print('- - - - - - - - - - - - - ')\n",
    "    print(df_to_clean.count()) #number of total rows after drop.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_to_clean):\n",
    "        create_date_from_string(df_to_clean, 'month', 'day', 'year')\n",
    "        remove_duplicates(df_to_clean)\n",
    "        drop_nulls_from_df(df_to_clean, True, ['No', 'year', 'month', 'day', 'hour', 'PM2.5', 'PM10', 'SO2', 'NO2',\n",
    "       'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM', 'station', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(data_directory):\n",
    "    #get the data files from the directory\n",
    "    data_files = [f for f in listdir(data_directory) if isfile(join(data_directory, f)) and f.endswith(\".csv\")]\n",
    "    df = pd.DataFrame() #initialize an empty dataframe\n",
    "    for data_file in data_files:\n",
    "        df_per_file = pd.read_csv(join(data_directory, data_file))\n",
    "        #concatonate the df_weekly dataframe we just generated with the others\n",
    "        df = pd.concat([df, df_per_file])\n",
    "\n",
    "    clean_data(df)    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derived Values from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aqi(df_to_add_aqi):    \n",
    "        # get more information from the error...\n",
    "        df_to_add_aqi['aqi'] = df_to_add_aqi.apply(lambda row: aqi.to_iaqi(aqi.POLLUTANT_PM25, str(row['PM10']), algo=aqi.ALGO_EPA), axis=1)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-67f5b81ae7c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalc_aqi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# test  = aqi.to_iaqi(aqi.POLLUTANT_PM10, '54', algo=aqi.ALGO_EPA)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print(test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-b104d0d2c9aa>\u001b[0m in \u001b[0;36mcalc_aqi\u001b[1;34m(df_to_add_aqi)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_aqi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_to_add_aqi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mdf_to_add_aqi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aqi'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_to_add_aqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_iaqi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOLLUTANT_PM25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PM2.5'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALGO_EPA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6877\u001b[0m         )\n\u001b[1;32m-> 6878\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6880\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 result = libreduction.compute_reduction(\n\u001b[1;32m--> 296\u001b[1;33m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-b104d0d2c9aa>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalc_aqi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_to_add_aqi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mdf_to_add_aqi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aqi'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_to_add_aqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_iaqi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOLLUTANT_PM25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PM2.5'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALGO_EPA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\aqi\\__init__.py\u001b[0m in \u001b[0;36mto_iaqi\u001b[1;34m(elem, cc, algo)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \"\"\"\n\u001b[0;32m     32\u001b[0m     \u001b[0m_aqi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_algo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_aqi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miaqi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mto_aqi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mccs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mALGO_EPA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\aqi\\algos\\base.py\u001b[0m in \u001b[0;36miaqi\u001b[1;34m(self, elem, cc)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0midx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# get corresponding AQI boundaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0maqilo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maqihi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpiecewise\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aqi'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m# equation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "calc_aqi(df_all)\n",
    "# test  = aqi.to_iaqi(aqi.POLLUTANT_PM10, '54', algo=aqi.ALGO_EPA)\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>...</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "      <th>station</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>aqi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "      <td>23.971319</td>\n",
       "      <td>120.979889</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>spring</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "      <td>23.971319</td>\n",
       "      <td>120.979889</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>spring</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "      <td>23.971319</td>\n",
       "      <td>120.979889</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>spring</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "      <td>23.971319</td>\n",
       "      <td>120.979889</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>spring</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "      <td>23.971319</td>\n",
       "      <td>120.979889</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>spring</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>35060</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>winter</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>35061</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>winter</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>35062</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>winter</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>35063</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>winter</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>35064</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Wanshouxigong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>winter</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382168 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          No  year  month  day  hour  PM2.5  PM10   SO2   NO2     CO  ...  \\\n",
       "0          1  2013      3    1     0    4.0   4.0   4.0   7.0  300.0  ...   \n",
       "1          2  2013      3    1     1    8.0   8.0   4.0   7.0  300.0  ...   \n",
       "2          3  2013      3    1     2    7.0   7.0   5.0  10.0  300.0  ...   \n",
       "3          4  2013      3    1     3    6.0   6.0  11.0  11.0  300.0  ...   \n",
       "4          5  2013      3    1     4    3.0   3.0  12.0  12.0  300.0  ...   \n",
       "...      ...   ...    ...  ...   ...    ...   ...   ...   ...    ...  ...   \n",
       "35059  35060  2017      2   28    19   11.0  32.0   3.0  24.0  400.0  ...   \n",
       "35060  35061  2017      2   28    20   13.0  32.0   3.0  41.0  500.0  ...   \n",
       "35061  35062  2017      2   28    21   14.0  28.0   4.0  38.0  500.0  ...   \n",
       "35062  35063  2017      2   28    22   12.0  23.0   4.0  30.0  400.0  ...   \n",
       "35063  35064  2017      2   28    23   13.0  19.0   4.0  38.0  600.0  ...   \n",
       "\n",
       "       DEWP  RAIN   wd  WSPM        station        lat        long       date  \\\n",
       "0     -18.8   0.0  NNW   4.4   Aotizhongxin  23.971319  120.979889 2013-03-01   \n",
       "1     -18.2   0.0    N   4.7   Aotizhongxin  23.971319  120.979889 2013-03-01   \n",
       "2     -18.2   0.0  NNW   5.6   Aotizhongxin  23.971319  120.979889 2013-03-01   \n",
       "3     -19.4   0.0   NW   3.1   Aotizhongxin  23.971319  120.979889 2013-03-01   \n",
       "4     -19.5   0.0    N   2.0   Aotizhongxin  23.971319  120.979889 2013-03-01   \n",
       "...     ...   ...  ...   ...            ...        ...         ...        ...   \n",
       "35059 -16.2   0.0   NW   2.4  Wanshouxigong        NaN         NaN 2017-02-28   \n",
       "35060 -15.1   0.0  WNW   0.9  Wanshouxigong        NaN         NaN 2017-02-28   \n",
       "35061 -13.3   0.0   NW   1.1  Wanshouxigong        NaN         NaN 2017-02-28   \n",
       "35062 -12.9   0.0  NNW   1.2  Wanshouxigong        NaN         NaN 2017-02-28   \n",
       "35063 -15.9   0.0  NNE   1.3  Wanshouxigong        NaN         NaN 2017-02-28   \n",
       "\n",
       "       season  aqi  \n",
       "0      spring   17  \n",
       "1      spring   17  \n",
       "2      spring   17  \n",
       "3      spring   17  \n",
       "4      spring   17  \n",
       "...       ...  ...  \n",
       "35059  winter   17  \n",
       "35060  winter   17  \n",
       "35061  winter   17  \n",
       "35062  winter   17  \n",
       "35063  winter   17  \n",
       "\n",
       "[382168 rows x 23 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_into_regions(df_to_bin):\n",
    "    # define regions\n",
    "    # Add new column to df 'region'\n",
    "    # calculate bins\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_into_seasons(df_to_bin,month_column):    \n",
    "    #https://seasonsyear.com/China\n",
    "    #summer = [6,7,8]\n",
    "    #fall = [9,10,11]\n",
    "    #winter = [12,1,2]\n",
    "    #spring = [3,4,5]    \n",
    "    # define seasons\n",
    "    # Add new column to df 'season'\n",
    "    # calculate bins\n",
    "    #hacky....but....fast...\n",
    "    seasons = ['winter','winter','spring','spring','spring', 'summer', 'summer', 'summer','fall','fall', 'fall','winter']    \n",
    "    df_to_bin['season'] = df_to_bin.apply(lambda row: seasons[row[month_column]-1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculte_average_of_bad_days(df_to_average):\n",
    "    #Running average of 7 days? for the two predictors\n",
    "    #should return a new dataframe?\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************\n",
      "Creating date column\n",
      "**************************\n",
      "**************************\n",
      "Removing Duplicates\n",
      "**************************\n",
      "number of duplicate rows:  0\n",
      "**************************\n",
      "Removing Nulls\n",
      "**************************\n",
      "- - - - - - - - - - - - - \n",
      "Before removing nulls\n",
      "- - - - - - - - - - - - - \n",
      "No              0\n",
      "year            0\n",
      "month           0\n",
      "day             0\n",
      "hour            0\n",
      "PM2.5        8739\n",
      "PM10         6449\n",
      "SO2          9021\n",
      "NO2         12116\n",
      "CO          20701\n",
      "O3          13277\n",
      "TEMP          398\n",
      "PRES          393\n",
      "DEWP          403\n",
      "RAIN          390\n",
      "wd           1822\n",
      "WSPM          318\n",
      "station         0\n",
      "lat        210384\n",
      "long       210384\n",
      "date            0\n",
      "dtype: int64\n",
      "- - - - - - - - - - - - - \n",
      "After removing nulls\n",
      "- - - - - - - - - - - - - \n",
      "No         382168\n",
      "year       382168\n",
      "month      382168\n",
      "day        382168\n",
      "hour       382168\n",
      "PM2.5      382168\n",
      "PM10       382168\n",
      "SO2        382168\n",
      "NO2        382168\n",
      "CO         382168\n",
      "O3         382168\n",
      "TEMP       382168\n",
      "PRES       382168\n",
      "DEWP       382168\n",
      "RAIN       382168\n",
      "wd         382168\n",
      "WSPM       382168\n",
      "station    382168\n",
      "lat        190907\n",
      "long       190907\n",
      "date       382168\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#actually laod all the data, clean it, and put it into a dataframe\n",
    "df_all = load_csv_data(\"data\")\n",
    "\n",
    "#run all of our calculations\n",
    "# calc_aiq_for_XX(df_all, 'XXX')\n",
    "# partition_into_regions(df_all)\n",
    "partition_into_seasons(df_all,'month')\n",
    "# df_moving_average = calculte_average_of_bad_days(df_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick list of all unique station names\n",
    "station_names = df_all.station.unique()\n",
    "station_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select just one station to examine\n",
    "#df = df_all[df_all['station'].isin(['Aotizhongxin','Changping','Dingling'])]\n",
    "df_A = df_all[df_all['station'].isin(['Aotizhongxin'])]\n",
    "print('length of A : {}'.format(len(df_A.index)))\n",
    "df_C = df_all[df_all['station'].isin(['Changping'])]\n",
    "print('length of C : {}'.format(len(df_C.index)))\n",
    "df_D = df_all[df_all['station'].isin(['Dingling'])]\n",
    "print('length of D : {}'.format(len(df_D.index)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lat longs:\n",
    "\n",
    "- Aotizhongxin :  (41.741127, 123.462775)\n",
    "- Changping :  (40.220585, 116.228038)\n",
    "- Dingling :  (40.289968, 116.237352)\n",
    "- Dongsi :  (39.929855, 116.421619)\n",
    "- Guanyuan :  (39.932482, 116.355741)\n",
    "- Gucheng :  (39.907599, 116.190328)\n",
    "- Huairou :  (40.605853, 116.622746)\n",
    "- Nongzhanguan :  (39.945631, 116.475666)\n",
    "- Shunyi :  (40.152315, 116.714525)\n",
    "- Tiantan :  (39.888430, 116.409856)\n",
    "- Wanliu :  (39.977951, 116.292273)\n",
    "- Wanghouxigong :  (,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df_all[['PM2.5','PM10','SO2','NO2','CO','O3','TEMP','PRES','DEWP','RAIN']]\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(df_numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_numeric.quantile(0.25)\n",
    "Q3 = df_numeric.quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a Histogram\n",
    "df_all.CO.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\n",
    "plt.title('Number of days by CO')\n",
    "plt.ylabel('Number of days')\n",
    "plt.xlabel('CO');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries\n",
    "fig = px.line(df_A, x='date', y='CO')\n",
    "# fig.add_scatter(x=df_all['date'], y=df_all['PM10'], mode='lines')\n",
    "# fig.add_scatter(x=df_all['date'], y=df_all['SO2'], mode='lines')\n",
    "#fig.add_scatter(x=df_all['date'], y=df_all['O3'], mode='lines')         \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.PM10.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\n",
    "plt.title('Number of days by PM10')\n",
    "plt.ylabel('Number of days')\n",
    "plt.xlabel('PM10');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the relations between the variables.\n",
    "plt.figure(figsize=(20,10))\n",
    "c= df_all.corr()\n",
    "sns.heatmap(c,cmap='BrBG',annot=True)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(df_all['NO2'], df_all['WSPM'])\n",
    "ax.set_xlabel('NO2')\n",
    "ax.set_ylabel('WSPM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_on_hover(marker):        \n",
    "    def callback(*args, **kwargs):        \n",
    "        global station_name\n",
    "        station_name = marker.name\n",
    "        print(station_name)\n",
    "        update_figure(station_name, data_name)\n",
    "    return callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bqplot import Lines, Figure, LinearScale, DateScale, Axis\n",
    "\n",
    "#some globals...not exactly the best way to do this buuut..\n",
    "global station_name\n",
    "global year\n",
    "global season\n",
    "global data_name\n",
    "\n",
    "station_name = 'Aotizhongxin'\n",
    "year = 2015\n",
    "season = 'summer'\n",
    "data_name = 'CO'\n",
    "\n",
    "\n",
    "\n",
    "#x_data = df_all[df_all.station == station_name and df_all.year == year and df_all.season == season][data_name].values\n",
    "y_data = df_all[(df_all['season'] == season) & (df_all['station'] == station_name) & (df_all['year'] == year)]['CO'].values\n",
    "x_data = df_all[(df_all['season'] == season) & (df_all['station'] == station_name) & (df_all['year'] == year)]['date'].values\n",
    "\n",
    "x_scale = LinearScale()\n",
    "\n",
    "date_start = dt.datetime(year, 1, 1)\n",
    "date_end = dt.datetime(year, 12, 31)\n",
    "\n",
    "date_scale = DateScale(min=date_start, max=date_end)\n",
    "\n",
    "lines = Lines(x=x_data, y=y_data ,scales={'x': date_scale, 'y': x_scale})\n",
    "lines\n",
    "\n",
    "ax_x = Axis(label='Year', scale=date_scale, num_ticks=10, tick_format='%y')\n",
    "ax_y = Axis(label=data_name.capitalize(), scale=x_scale, orientation='vertical', side='left')\n",
    "\n",
    "figure = Figure(axes=[ax_x, ax_y], title=station_name, marks=[lines], animation_duration=500,\n",
    "                 layout={'max_height': '250px', 'max_width': '400px'})\n",
    "\n",
    "\n",
    "figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_figure('Aotizhongxin', 'CO', year=2013, season='spring')\n",
    "#update_figure('Aotizhongxin', 'CO', year=2013, season='summer')\n",
    "#update_figure('Aotizhongxin', 'CO', year=2013, season='fall')\n",
    "#update_figure('Aotizhongxin', 'CO', year=2013, season='winter')\n",
    "\n",
    "update_figure('Aotizhongxin', 'CO', 2013, 'fall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = Map(center=(39.987916, 116.383936), zoom=12)\n",
    "\n",
    "stations = {\n",
    "    'Aotizhongxin' : (39.987916, 116.383936),\n",
    "    'Changping' : (40.220585, 116.228038),\n",
    "    'Dingling' : (40.289968, 116.237352),\n",
    "    'Dongsi' : (39.929855, 116.421619),\n",
    "    'Guanyuan' : (39.932482, 116.355741),\n",
    "    'Gucheng' : (39.907599, 116.190328),\n",
    "    'Huairou' : (40.605853, 116.622746),\n",
    "    'Nongzhanguan' : (39.945631, 116.475666),\n",
    "    'Shunyi' : (40.152315, 116.714525),\n",
    "    'Tiantan' : (39.888430, 116.409856),\n",
    "    'Wanliu' : (39.977951, 116.292273)\n",
    "}\n",
    "\n",
    "for station in stations.items():\n",
    "    marker = Marker(location=station[1], draggable=False, title=station[0], name=station[0])\n",
    "    marker.on_mouseover(get_on_hover(marker))\n",
    "    m.add_layer(marker);    \n",
    "    #m.add_layer(Marker(location=station[1], draggable=False));\n",
    "\n",
    "# marker = Marker(location=center, draggable=False)\n",
    "# m.add_layer(marker);\n",
    "\n",
    "map_layer = basemap_to_tiles(basemaps.CartoDB.Positron)\n",
    "m.add_layer(map_layer)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_control1 = WidgetControl(widget=figure, position='bottomright')\n",
    "m.add_control(widget_control1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_figure(station_name, data_name, year, season):\n",
    "    \n",
    "    year_start = 2013\n",
    "    year_end = 2016\n",
    "    \n",
    "    if(year == 0 and season == ''):\n",
    "        y_data = df_all[(df_all['season'] == season) & (df_all['station'] == station_name) & (df_all['year'] == year)][data_name].values\n",
    "        x_data = df_all[(df_all['season'] == season) & (df_all['station'] == station_name) & (df_all['year'] == year)]['date'].values\n",
    "        \n",
    "        year_start = year\n",
    "        year_end = year\n",
    "        \n",
    "    else :\n",
    "        y_data = df_all[(df_all['station'] == station_name)][data_name].values\n",
    "        x_data = df_all[(df_all['station'] == station_name)]['date'].values\n",
    "           \n",
    "    lines.y = y_data\n",
    "    lines.x = x_data\n",
    "    \n",
    "    ax_y.label = data_name.capitalize()\n",
    "    figure.title = station_name\n",
    "    \n",
    "    date_start = dt.datetime(year_start, 1, 1)\n",
    "    date_end = dt.datetime(year_end, 12, 31)\n",
    "    date_scale = DateScale(min=date_start, max=date_end)\n",
    "    lines.scales={'x': date_scale, 'y': x_scale}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown = Dropdown(\n",
    "    options=['CO', 'PM10', 'PM2.5'],\n",
    "    value=data_name,\n",
    "    description='Plotting:'\n",
    ")\n",
    "\n",
    "def data_on_click(change):\n",
    "    global data_name\n",
    "    data_name = change['new']\n",
    "    update_figure(station_name, data_name, 2013, 'winter')\n",
    "\n",
    "dropdown.observe(data_on_click, 'value')\n",
    "\n",
    "widget_control2 = WidgetControl(widget=dropdown, position='bottomleft')\n",
    "\n",
    "m.add_control(widget_control2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_year = Dropdown(\n",
    "    options=['2013', '2014', '2015', '2016'],\n",
    "    value=year,\n",
    "    description='Plotting:'\n",
    ")\n",
    "\n",
    "def year_on_click(change):\n",
    "    global data_year\n",
    "    year = change['new']\n",
    "    update_figure(station_name, data_name, year)\n",
    "\n",
    "dropdown_year.observe(year_on_click, 'value')\n",
    "\n",
    "widget_control_year = WidgetControl(widget=dropdown_year, position='bottomleft')\n",
    "\n",
    "m.add_control(widget_control_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_season = Dropdown(\n",
    "    options=['spring', 'summer', 'winter', 'fall'],\n",
    "    value=season,\n",
    "    description='Plotting:'\n",
    ")\n",
    "\n",
    "def data_on_click(change):\n",
    "    global data_name\n",
    "    data_name = change['new']\n",
    "    update_figure(station_name, data_name)\n",
    "\n",
    "dropdown.observe(data_on_click, 'value')\n",
    "\n",
    "widget_control2 = WidgetControl(widget=dropdown, position='bottomleft')\n",
    "\n",
    "m.add_control(widget_control2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df_all[(df_all['season'] == %) & (df_all['station'] == 'Aotizhongxin') & (df_all['year'] == 2016)]['CO'].values\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
