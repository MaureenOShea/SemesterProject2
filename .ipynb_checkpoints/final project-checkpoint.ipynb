{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Aotizhongxin, Changping, Dingling (Michael) \n",
    " - Dongsi, Guanyuan, Gucheng (David) \n",
    " - Huairou, Nongzhanguan, Shunyi (Muareen) \n",
    " - Tiantan, Wanliu, and Wanghouxigong (Anna)\n",
    " \n",
    " \n",
    " \n",
    " # some work to do:\n",
    "  \n",
    "1. Calculate AQI for each day for PMP10 and PM2.5\n",
    "2. Subset the data into geographic regions\n",
    "    2.1 Subset the data by seasons\n",
    "3. General trend for some attributes?\n",
    "        Create AIQ\n",
    "        Avg number of really bad days?                        \n",
    "4. Make cool looking plots/graphs with the data MAPS!\n",
    "5. Analysis of those plots/graphs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns #visualisation\n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "import seaborn as sns #visualisation\n",
    "%matplotlib inline \n",
    "sns.set(color_codes=True)\n",
    "import plotly.express as px\n",
    "import datetime as dt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "\n",
    "#conda install -c conda-forge ipyleaflet\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, Marker, Heatmap, WidgetControl, FullScreenControl\n",
    "from bqplot import Lines, Figure, LinearScale, DateScale, Axis\n",
    "from ipywidgets import Dropdown\n",
    "\n",
    "import aqi\n",
    "import calendar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and cleaning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_from_string(df_to_clean, month_column, day_column, year_column):\n",
    "    #add correct data column\n",
    "    print('**************************')\n",
    "    print('Creating date column')\n",
    "    print('**************************')\n",
    "    df_to_clean['date_string'] = df_to_clean.apply(lambda row: str(row[month_column])+'-'+str(row[day_column])+'-'+str(row[year_column]), axis=1)\n",
    "    df_to_clean['date'] = df_to_clean.apply(lambda row: dt.datetime(row[year_column], row[month_column], row[day_column]), axis=1)\n",
    "    \n",
    "    #df_to_clean['date_2'] =  pd.to_datetime(df_to_clean['date'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df_to_clean):    \n",
    "    print('**************************')\n",
    "    print('Removing Duplicates')\n",
    "    print('**************************')\n",
    "    duplicate_rows_df = df_to_clean[df_to_clean.duplicated()]\n",
    "    print('number of duplicate rows: ', len(duplicate_rows_df.index))\n",
    "    df_to_clean.drop_duplicates(inplace=True)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drop_nulls_from_df(df_to_clean, drop_rows,column_names=[]):\n",
    "    if column_names == []:\n",
    "        column_names == column_names.append(df_to_clean.columns)\n",
    "    print('**************************')\n",
    "    print('Removing Nulls')\n",
    "    print('**************************') \n",
    "    \n",
    "    print('- - - - - - - - - - - - - ')\n",
    "    print('Before removing nulls')\n",
    "    print('- - - - - - - - - - - - - ')\n",
    "    print(df_to_clean.isnull().sum()) # Number of rows with nulls that we are dropping    \n",
    "    \n",
    "    if(drop_rows):\n",
    "        df_to_clean.dropna(inplace=True, subset=column_names) \n",
    "    \n",
    "    \n",
    "    print('- - - - - - - - - - - - - ')\n",
    "    print('After removing nulls')\n",
    "    print('- - - - - - - - - - - - - ')\n",
    "    print(df_to_clean.count()) #number of total rows after drop.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_to_clean):\n",
    "        create_date_from_string(df_to_clean, 'month', 'day', 'year')\n",
    "        remove_duplicates(df_to_clean)\n",
    "        drop_nulls_from_df(df_to_clean, True, ['No', 'year', 'month', 'day', 'hour', 'PM2.5', 'PM10', 'SO2', 'NO2',\n",
    "       'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'wd', 'WSPM', 'station', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data_by_day(df_to_group):\n",
    "    df_grouped = df_to_group.groupby(['station',\"month\", \"day\",'year'], as_index=False)[['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3','TEMP','PRES','DEWP','RAIN','WSPM']].max()\n",
    "    return df_grouped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(data_directory):\n",
    "    #get the data files from the directory\n",
    "    data_files = [f for f in listdir(data_directory) if isfile(join(data_directory, f)) and f.endswith(\".csv\")]\n",
    "    df = pd.DataFrame() #initialize an empty dataframe\n",
    "    for data_file in data_files:\n",
    "        df_per_file = pd.read_csv(join(data_directory, data_file))\n",
    "        #concatonate the df_weekly dataframe we just generated with the others\n",
    "        df = pd.concat([df, df_per_file])\n",
    "\n",
    "    clean_data(df)    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derived Values from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_aqi(row,aqi_measure, column_name):\n",
    "    try:        \n",
    "        return aqi.to_iaqi(aqi_measure, str(row[column_name]), algo=aqi.ALGO_EPA)\n",
    "    except IndexError:\n",
    "        #the value is too big for the calculator, will calculate the max value instead.\n",
    "        return 501\n",
    "    except Exception as e :\n",
    "        print(e)\n",
    "        \n",
    "\n",
    "def calc_aqis(df_to_add_aqi):    \n",
    "        # get more information from the error...\n",
    "        df_to_add_aqi['aqi_PM10'] = df_to_add_aqi.apply(lambda row: apply_aqi(row,aqi.POLLUTANT_PM10, \"PM10\"), axis=1)\n",
    "        df_to_add_aqi['aqi_PM2.5'] = df_to_add_aqi.apply(lambda row: apply_aqi(row,aqi.POLLUTANT_PM25, \"PM2.5\"), axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_into_regions(df_to_bin):\n",
    "    # define regions\n",
    "    # Add new column to df 'region'\n",
    "    # calculate bins\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_into_seasons(df_to_bin,month_column):    \n",
    "    #https://seasonsyear.com/China\n",
    "    #summer = [6,7,8]\n",
    "    #fall = [9,10,11]\n",
    "    #winter = [12,1,2]\n",
    "    #spring = [3,4,5]    \n",
    "    # define seasons\n",
    "    # Add new column to df 'season'\n",
    "    # calculate bins\n",
    "    #hacky....but....fast...\n",
    "    seasons = ['winter','winter','spring','spring','spring', 'summer', 'summer', 'summer','fall','fall', 'fall','winter']    \n",
    "    df_to_bin['season'] = df_to_bin.apply(lambda row: seasons[row[month_column]-1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculte_average_of_bad_days(df_to_average):\n",
    "    #Running average of 7 days? for the two predictors\n",
    "    #should return a new dataframe?\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the clean functions and the derived data functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actually laod all the data, clean it, and put it into a dataframe\n",
    "df_all = load_csv_data(\"data\")\n",
    "\n",
    "#run all of our calculations\n",
    "# partition_into_regions(df_all)\n",
    "# df_moving_average = calculte_average_of_bad_days(df_all)\n",
    "\n",
    "df_group = group_data_by_day(df_all)\n",
    "calc_aqis(df_group)\n",
    "partition_into_seasons(df_group,'month')\n",
    "create_date_from_string(df_group, 'month','day','year')\n",
    "\n",
    "# sorted_df = df.sort_values(by = 'date')\n",
    "df = df_group.sort_values(by = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick list of all unique station names\n",
    "station_names = df_all.station.unique()\n",
    "station_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select just one station to examine\n",
    "#df = df_all[df_all['station'].isin(['Aotizhongxin','Changping','Dingling'])]\n",
    "df_A = df[df['station'].isin(['Aotizhongxin'])]\n",
    "print('length of A : {}'.format(len(df_A.index)))\n",
    "df_C = df[df['station'].isin(['Changping'])]\n",
    "print('length of C : {}'.format(len(df_C.index)))\n",
    "df_D = df[df['station'].isin(['Dingling'])]\n",
    "print('length of D : {}'.format(len(df_D.index)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lat longs:\n",
    "\n",
    "- Aotizhongxin :  (41.741127, 123.462775)\n",
    "- Changping :  (40.220585, 116.228038)\n",
    "- Dingling :  (40.289968, 116.237352)\n",
    "- Dongsi :  (39.929855, 116.421619)\n",
    "- Guanyuan :  (39.932482, 116.355741)\n",
    "- Gucheng :  (39.907599, 116.190328)\n",
    "- Huairou :  (40.605853, 116.622746)\n",
    "- Nongzhanguan :  (39.945631, 116.475666)\n",
    "- Shunyi :  (40.152315, 116.714525)\n",
    "- Tiantan :  (39.888430, 116.409856)\n",
    "- Wanliu :  (39.977951, 116.292273)\n",
    "- Wanghouxigong :  (,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df[['PM2.5','PM10','SO2','NO2','CO','O3','TEMP','PRES','DEWP','RAIN']]\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(df_numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df_numeric.quantile(0.25)\n",
    "Q3 = df_numeric.quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a Histogram\n",
    "df.CO.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\n",
    "plt.title('Number of days by CO')\n",
    "plt.ylabel('Number of days')\n",
    "plt.xlabel('CO');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a Histogram\n",
    "df.PM10.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\n",
    "plt.title('Number of days by PM10')\n",
    "plt.ylabel('Number of days')\n",
    "plt.xlabel('PM10');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a Histogram\n",
    "df['PM2.5'].value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\n",
    "plt.title('Number of days by PM2.5')\n",
    "plt.ylabel('Number of days')\n",
    "plt.xlabel('PM2.5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries\n",
    "\n",
    "fig = px.line(df_A, x='date_string', y='PM10')\n",
    "# fig.add_scatter(x=df_all['date'], y=df_all['PM10'], mode='lines')\n",
    "# fig.add_scatter(x=df_all['date'], y=df_all['SO2'], mode='lines')\n",
    "#fig.add_scatter(x=df_all['date'], y=df_all['O3'], mode='lines')         \n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.PM10.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\n",
    "plt.title('Number of days by PM10')\n",
    "plt.ylabel('Number of days')\n",
    "plt.xlabel('PM10');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Finding the relations between the variables.\n",
    "plt.figure(figsize=(20,10))\n",
    "c = df.corr()\n",
    "sns.heatmap(c,cmap='BrBG',annot=True)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(df['NO2'], df['WSPM'])\n",
    "ax.set_xlabel('NO2')\n",
    "ax.set_ylabel('WSPM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_on_hover(marker,global_data_name, global_year, global_month):  \n",
    "    print(global_year)\n",
    "    def callback(*args, **kwargs):        \n",
    "        global_station_name = marker.name\n",
    "        #print(args)\n",
    "        #update_figure(global_station_name, global_data_name, global_year, global_month)\n",
    "    return callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#some globals...not exactly the best way to do this buuut..\n",
    "global global_station_name\n",
    "global global_year\n",
    "global global_month\n",
    "global global_data_name\n",
    "\n",
    "global_station_name = 'Aotizhongxin'\n",
    "global_year = 2015\n",
    "global_month = 1\n",
    "global_data_name = 'CO'\n",
    "\n",
    "\n",
    "y_data = df[(df['month'] == global_month) & (df['station'] == global_station_name) & (df['year'] == global_year)][global_data_name].values\n",
    "x_data = df[(df['month'] == global_month) & (df['station'] == global_station_name) & (df['year'] == global_year)]['date'].values\n",
    "\n",
    "x_scale = LinearScale()\n",
    "\n",
    "date_start = dt.datetime(global_year, global_month, 1)\n",
    "date_end = dt.datetime(global_year, global_month, 31)\n",
    "\n",
    "date_scale = DateScale(min=date_start, max=date_end)\n",
    "\n",
    "lines = Lines(x=x_data, y=y_data ,scales={'x': date_scale, 'y': x_scale})\n",
    "label = calendar.month_name[global_month] + ' - ' + str(global_year)\n",
    "\n",
    "\n",
    "ax_x = Axis(label=label, scale=date_scale, num_ticks=10, tick_format='%d')\n",
    "ax_y = Axis(label=global_data_name.capitalize(), scale=x_scale, orientation='vertical', side='left')\n",
    "\n",
    "figure = Figure(axes=[ax_x, ax_y], title=global_station_name, marks=[lines], animation_duration=500,\n",
    "                 layout={'max_height': '250px', 'max_width': '400px'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = Map(center=(39.987916, 116.383936), zoom=12)\n",
    "\n",
    "stations = {\n",
    "    'Aotizhongxin' : (39.987916, 116.383936),\n",
    "    'Changping' : (40.220585, 116.228038),\n",
    "    'Dingling' : (40.289968, 116.237352),\n",
    "    'Dongsi' : (39.929855, 116.421619),\n",
    "    'Guanyuan' : (39.932482, 116.355741),\n",
    "    'Gucheng' : (39.907599, 116.190328),\n",
    "    'Huairou' : (40.605853, 116.622746),\n",
    "    'Nongzhanguan' : (39.945631, 116.475666),\n",
    "    'Shunyi' : (40.152315, 116.714525),\n",
    "    'Tiantan' : (39.888430, 116.409856),\n",
    "    'Wanliu' : (39.977951, 116.292273)\n",
    "}\n",
    "\n",
    "for station in stations.items():\n",
    "    marker = Marker(location=station[1], draggable=False, title=station[0], name=station[0])\n",
    "    marker.on_mouseover(get_on_hover(marker,global_data_name, global_year, global_month ))\n",
    "    m.add_layer(marker);    \n",
    "    #m.add_layer(Marker(location=station[1], draggable=False));\n",
    "\n",
    "# marker = Marker(location=center, draggable=False)\n",
    "# m.add_layer(marker);\n",
    "\n",
    "map_layer = basemap_to_tiles(basemaps.CartoDB.Positron)\n",
    "m.add_layer(map_layer)\n",
    "m.add_control(FullScreenControl())\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_control1 = WidgetControl(widget=figure, position='bottomright')\n",
    "m.add_control(widget_control1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_figure(station_name, data_name, year, month):\n",
    "\n",
    "\n",
    "\n",
    "    if(year == 999):\n",
    "        y_data = df[(df['station'] == station_name)][data_name].values\n",
    "        x_data = df[df['station'] == station_name]['date'].values\n",
    "        \n",
    "        year_start = 2013\n",
    "        year_end = 2016\n",
    "        month_start = 1\n",
    "        month_end = 12\n",
    "        \n",
    "        date_start = dt.datetime(2013, 1, 1)\n",
    "        date_end = dt.datetime(2016, 12, 31)\n",
    "        \n",
    "        ax_x.label = \"2013 to 2016\"\n",
    "        ax_x.tick_format = '%Y'\n",
    "    \n",
    "    if(month == 999 and year != 999):\n",
    "        y_data = df[(df['station'] == station_name) & (df['year'] == year)][data_name].values\n",
    "        x_data = df[(df['station'] == station_name) & (df['year'] == year)]['date'].values\n",
    "\n",
    "        date_start = dt.datetime(year, 1, 1)\n",
    "        date_end = dt.datetime(year, 12, 31)\n",
    "        \n",
    "        ax_x.label = str(year)\n",
    "        ax_x.tick_format = '%b'\n",
    "\n",
    "        \n",
    "    if ((month != 999) and (year != 999) ):\n",
    "        y_data = df[(df['month'] == month) & (df['station'] == station_name) & (df['year'] == year)][data_name].values\n",
    "        x_data = df[(df['month'] == month) & (df['station'] == station_name) & (df['year'] == year)]['date'].values\n",
    "\n",
    "        date_start = dt.datetime(year, month, 1)\n",
    "        date_end = dt.datetime(year, month, calendar.monthrange(year, month)[1])\n",
    "        \n",
    "        ax_x.label = calendar.month_name[month] + \" - \" + str(year)\n",
    "        ax_x.tick_format = '%d'\n",
    "\n",
    "           \n",
    "    lines.y = y_data\n",
    "    lines.x = x_data\n",
    "    \n",
    "    ax_y.label = data_name.capitalize()\n",
    "    figure.title = station_name  \n",
    "    \n",
    "\n",
    "    date_scale = DateScale(min=date_start, max=date_end)\n",
    "    ax_x.scale = date_scale\n",
    "    lines.scales={'x': date_scale, 'y': x_scale}\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown = Dropdown(\n",
    "    options=['CO', 'PM10', 'PM2.5'],\n",
    "    value=global_data_name,\n",
    "    description='Measurement:'\n",
    ")\n",
    "\n",
    "def data_on_click(change):\n",
    "    global_data_name = change['new']\n",
    "    update_figure(global_station_name, global_data_name, global_year, global_month)\n",
    "\n",
    "    \n",
    "dropdown.observe(data_on_click, 'value')\n",
    "\n",
    "widget_control2 = WidgetControl(widget=dropdown, position='bottomleft')\n",
    "\n",
    "m.add_control(widget_control2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_year = Dropdown(\n",
    "    options=[2013, 2014, 2015, 2016,'All Years'],\n",
    "    value=global_year,\n",
    "    description='Year:'\n",
    ")\n",
    "\n",
    "def year_on_click(change):\n",
    "    global_year = change['new']\n",
    "    if global_year == 'All Years':\n",
    "        global_year = 999\n",
    "        global_data_month = 999\n",
    "    update_figure(global_station_name, global_data_name, global_year, global_month)\n",
    "\n",
    "dropdown_year.observe(year_on_click, 'value')\n",
    "\n",
    "widget_control_year = WidgetControl(widget=dropdown_year, position='bottomleft')\n",
    "\n",
    "m.add_control(widget_control_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_month = Dropdown(\n",
    "    options=[1,2,3,4,5,6,7,8,9,10,11,12,'All Months'],\n",
    "    value=global_month,\n",
    "    description='Month:'\n",
    ")\n",
    "\n",
    "def month_on_click(change):\n",
    "    global_month = change['new']\n",
    "    if global_month == 'All Months':\n",
    "        global_month = 999\n",
    "        \n",
    "    update_figure(global_station_name, global_data_name, global_year, global_month)\n",
    "\n",
    "dropdown_month.observe(month_on_click, 'value')\n",
    "\n",
    "widget_control_month = WidgetControl(widget=dropdown_month, position='bottomleft')\n",
    "\n",
    "m.add_control(widget_control_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
